{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: utils\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "cudnn.benchmark = True\n",
    "\n",
    "class Average_IOU_Meter():\n",
    "    def __init__(self, args, batches):\n",
    "        self.args = args\n",
    "        self.cal_size = batches - 1\n",
    "        self.iou_vars = np.zeros( ( self.cal_size, args.num_classes-1, ) )\n",
    "        self.idx = 0\n",
    "    def update(self, niov):\n",
    "        self.iou_vars[self.idx,:] = niov\n",
    "        self.idx +=1\n",
    "\n",
    "    def reset(self):\n",
    "        self.iou_vars = np.zeros(( self.cal_size, self.args.num_classes-1, ))\n",
    "        self.idx = 0\n",
    "\n",
    "    def cal_avg(self):\n",
    "        result = np.zeros( (self.args.num_classes-1, ) )\n",
    "        for ci in range(self.args.num_classes-1):\n",
    "            result[ci] = np.nanmean( self.iou_vars[:,ci])\n",
    "\n",
    "        return result\n",
    "\n",
    "class data_augment:\n",
    "    def __init__(self, args, split = 'train'):\n",
    "        self.args = args\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        self.scale_factor = 16\n",
    "        self.base_size = 2048\n",
    "        self.ignore_label = args.num_classes-1\n",
    "        if split == \"train\":\n",
    "            self.crop_size = (256, 512)  ## 训练时所用的裁剪大小\n",
    "        else:\n",
    "            self.crop_size = (256, 512)\n",
    "\n",
    "        self.label_mapping = {-1: self.ignore_label, 0: self.ignore_label,\n",
    "                              1: self.ignore_label, 2: self.ignore_label,\n",
    "                              3: self.ignore_label, 4: self.ignore_label,\n",
    "                              5: self.ignore_label, 6: self.ignore_label,\n",
    "                              7: 0,  # road\n",
    "                              8: 1,  # sidewalk\n",
    "                              9: self.ignore_label,\n",
    "                              10: self.ignore_label,\n",
    "                              11: 2, # building\n",
    "                              12: self.ignore_label,\n",
    "                              13: self.ignore_label,\n",
    "                              14: self.ignore_label,\n",
    "                              15: self.ignore_label,\n",
    "                              16: self.ignore_label,\n",
    "                              17: 3, # pole\n",
    "                              18: self.ignore_label,\n",
    "                              19: 4, # traffic light\n",
    "                              20: 5, # traffic sign\n",
    "                              21: 6, # vegetation\n",
    "                              22: 7, # terrain\n",
    "                              23: 8, # sky\n",
    "                              24: 9, # person\n",
    "                              25: 10, # rider\n",
    "                              26: 11, # car\n",
    "                              27: self.ignore_label,\n",
    "                              28: self.ignore_label,\n",
    "                              29: self.ignore_label,\n",
    "                              30: self.ignore_label,\n",
    "                              31: self.ignore_label,\n",
    "                              32: self.ignore_label,\n",
    "                              33: self.ignore_label}\n",
    "\n",
    "\n",
    "    def pad_image(self, image, h, w, size, padvalue):\n",
    "        pad_image = image.copy()\n",
    "        pad_h = max(size[0] - h, 0)\n",
    "        pad_w = max(size[1] - w, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            pad_image = cv2.copyMakeBorder(image, 0, pad_h, 0,\n",
    "                                           pad_w, cv2.BORDER_CONSTANT,\n",
    "                                           value=padvalue)\n",
    "\n",
    "        return pad_image\n",
    "\n",
    "    def rand_crop(self, image, label):\n",
    "        \"\"\"\n",
    "\n",
    "        :param image: [H, W, C]\n",
    "        :param label: [H, W]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        h, w = image.shape[:-1]\n",
    "        image = self.pad_image(image, h, w, self.crop_size,\n",
    "                          (0.0, 0.0, 0.0))\n",
    "        label = self.pad_image(label, h, w, self.crop_size,\n",
    "                          (self.ignore_label,))\n",
    "\n",
    "        new_h, new_w = label.shape\n",
    "        x = random.randint(0, new_w - self.crop_size[1])\n",
    "        y = random.randint(0, new_h - self.crop_size[0])\n",
    "        image = image[y:y + self.crop_size[0], x:x + self.crop_size[1]]\n",
    "        label = label[y:y + self.crop_size[0], x:x + self.crop_size[1]]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def multi_scale_aug(self,image, label=None,\n",
    "                        rand_scale=1, rand_cro=True):\n",
    "        long_size = np.int(self.base_size * rand_scale + 0.5)\n",
    "        h, w = image.shape[:2]\n",
    "        if h > w:\n",
    "            new_h = long_size\n",
    "            new_w = np.int(w * long_size / h + 0.5)\n",
    "        else:\n",
    "            new_w = long_size\n",
    "            new_h = np.int(h * long_size / w + 0.5)\n",
    "\n",
    "        image = cv2.resize(image, (new_w, new_h),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "        if label is not None:\n",
    "            label = cv2.resize(label, (new_w, new_h),\n",
    "                               interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        if rand_cro:\n",
    "            image, label = self.rand_crop(image, label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def label_transform(self, label):\n",
    "        return np.array(label).astype('int32')\n",
    "\n",
    "    def gen_sample_resize(self, img, label):\n",
    "        rand_scale = 0.5 + random.randint(0, self.scale_factor) / 10.0\n",
    "        image, label = self.multi_scale_aug(img, label,\n",
    "                                            rand_scale=rand_scale)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return image, label\n",
    "\n",
    "    def gen_sample_simplified(self,image, target):\n",
    "        image = torch.from_numpy(cv2.resize(image,dsize=[138,266]))\n",
    "        target = torch.from_numpy(cv2.resize(target,dsize=[138,266]))\n",
    "        # Random crop\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(128, 256))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        target = TF.crop(target, i, j, h, w)\n",
    "        # Random horizontal flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            target = TF.hflip(target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def gen_sample(self, image, label, is_flip=True):\n",
    "        \"\"\"\n",
    "        this function is used to generate samples with combination of transforms\n",
    "        :param image:\n",
    "        :param label:\n",
    "        :param is_flip:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        image, label = self.rand_crop(image, label)\n",
    "        image = image.transpose((2,0,1))\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def input_transform(self, image):\n",
    "        image = image.astype(np.float32)[:, :, ::-1]\n",
    "        image = image / 255.0\n",
    "        image -= self.mean\n",
    "        image /= self.std\n",
    "        return image\n",
    "\n",
    "    def convert_label(self,label, inverse=False):\n",
    "        temp = label.copy()\n",
    "        if inverse:\n",
    "            for v, k in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        else:\n",
    "            for k, v in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        return label\n",
    "\n",
    "class data_sampler:\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def cv2_sampler(self, index) :\n",
    "        image = cv2.imread(self.images[index], cv2.IMREAD_COLOR)\n",
    "        label = cv2.imread(self.labels[index], cv2.IMREAD_GRAYSCALE)\n",
    "        return image, label\n",
    "\n",
    "def class_to_rgb(pred):\n",
    "    \"\"\"\n",
    "\n",
    "    :param pred: 输入图片的张量\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        0: (0,0,0),\n",
    "        1: (0, 255, 0),\n",
    "        2: (0, 0, 255),\n",
    "        3: (0, 255, 255),\n",
    "        4: (128, 0, 0),\n",
    "        5: (0, 128, 0),\n",
    "        6: (0, 0, 128),\n",
    "        7: (128, 128, 0),\n",
    "        8: (128, 0, 128),\n",
    "        9: (128, 128, 128),\n",
    "        10: (64, 0, 0),\n",
    "        11: (0, 64, 0),\n",
    "        12: (255, 255, 0),\n",
    "        13: (0, 128, 128),\n",
    "        14: (0,0,64),\n",
    "        15:(255,255,255)\n",
    "\n",
    "    }\n",
    "\n",
    "    rgbimg = torch.zeros((3, pred.shape[0], pred.shape[1]), dtype=torch.uint8)\n",
    "    for k in mapping.keys():\n",
    "        rgbimg[0][pred == k] = mapping[k][0]\n",
    "        rgbimg[1][pred == k] = mapping[k][1]\n",
    "        rgbimg[2][pred == k] = mapping[k][2]\n",
    "\n",
    "    return rgbimg\n",
    "def visual(tensor):\n",
    "    unloader = transforms.ToPILImage()\n",
    "    img = unloader(tensor)\n",
    "    plt.imshow(img)\n",
    "    plt.pause(4)\n",
    "\n",
    "def reconstruct_mask(re_key:list, range_cls:list):\n",
    "    re_list = list(set(range_cls) - set(re_key))\n",
    "    re_dic = list(zip(re_list, [i for i in range(len(re_list))]))\n",
    "    re_key_dic = [(i, len(re_list) ) for i in re_key]\n",
    "    return( re_dic + re_key_dic)\n",
    "\n",
    "def manual_inference_time(model,batch):\n",
    "    \"\"\"\n",
    "    measuring inference time each batch(CUDA version)\n",
    "    :param model:\n",
    "    :param dummy_input:\n",
    "    :param batch:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    device = 'cuda:0'\n",
    "    model = model.to(device)\n",
    "    repetitions = 300\n",
    " #   dummy_input = torch.rand(1, 3, 256, 256).to(device)\n",
    "    batch = batch.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print('warm up ...\\n')\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.synchronize()\n",
    "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "        starter.record()\n",
    "        output = model(batch)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize()  # 等待GPU任务完成\n",
    "        curr_time = starter.elapsed_time(ender)  # 从 starter 到 ender 之间用时,单位为毫秒\n",
    "    return\n",
    "\n",
    "    avg = timings.sum() / repetitions\n",
    "    print('\\navg={}\\n'.format(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: 准备数据集\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CityscapesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, args,split='train', mode='fine', augment=True):\n",
    "\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.mode = 'gtFine' if mode == 'fine' else 'gtCoarse'\n",
    "        self.images_dir = os.path.join(self.root, 'leftImg8bit', split)\n",
    "        self.targets_dir = os.path.join(self.root, self.mode, split)\n",
    "        self.split = split\n",
    "        self.augment = augment\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "        self.args =args\n",
    "        # =============================================\n",
    "        # Check that inputs are valid\n",
    "        # =============================================\n",
    "        if mode not in ['fine', 'coarse']:\n",
    "            raise ValueError('Invalid mode! Please use mode=\"fine\" or mode=\"coarse\"')\n",
    "        if mode == 'fine' and split not in ['train', 'test', 'val']:\n",
    "            raise ValueError('Invalid split for mode \"fine\"! Please use split=\"train\", split=\"test\" or split=\"val\"')\n",
    "        elif mode == 'coarse' and split not in ['train', 'train_extra', 'val']:\n",
    "            raise ValueError(\n",
    "                'Invalid split for mode \"coarse\"! Please use split=\"train\", split=\"train_extra\" or split=\"val\"')\n",
    "        if not os.path.isdir(self.images_dir) or not os.path.isdir(self.targets_dir):\n",
    "            raise RuntimeError('Dataset not found or incomplete. Please make sure all required folders for the'\n",
    "                               ' specified \"split\" and \"mode\" are inside the \"root\" directory')\n",
    "\n",
    "        # =============================================\n",
    "        # Read in the paths to all images\n",
    "        # =============================================\n",
    "        for city in os.listdir(self.images_dir):\n",
    "            img_dir = os.path.join(self.images_dir, city)\n",
    "            target_dir = os.path.join(self.targets_dir, city)\n",
    "            for file_name in os.listdir(img_dir):\n",
    "                if '.ipynb' not in file_name:\n",
    "                    self.images.append(os.path.join(img_dir, file_name))\n",
    "                    target_name = '{}_{}'.format(file_name.split('_leftImg8bit')[0],\n",
    "                                                 '{}_labelIds.png'.format(self.mode))\n",
    "                    # target_name = '{}_{}'.format(file_name.split('_leftImg8bit')[0], '{}_color.png'.format(self.mode))\n",
    "                    self.targets.append(os.path.join(target_dir, target_name))\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of images: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Split: {}\\n'.format(self.split)\n",
    "        fmt_str += '    Mode: {}\\n'.format(self.mode)\n",
    "        fmt_str += '    Augment: {}\\n'.format(self.augment)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        return fmt_str\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # first load the RGB image\n",
    "        data_slr = data_sampler(self.images, self.targets)\n",
    "        image, target = data_slr.cv2_sampler(index)\n",
    "\n",
    "        ## gen_sample function will do the augmentation\n",
    "        data_handler = data_augment(self.args, self.split)\n",
    "        target = data_handler.convert_label(target)\n",
    "    #    image, target = data_handler.gen_sample_resize(image, target)\n",
    "    #    image, target = data_handler.gen_sample_simplified(image, target)\n",
    "        image, target = data_handler.gen_sample(image, target)\n",
    "\n",
    "        image = torch.from_numpy(image.copy()).float()\n",
    "\n",
    "        target = torch.from_numpy(np.array(target, dtype=np.uint8))\n",
    "        # print(target)\n",
    "        # utils.visual(target)\n",
    "        target = target.long()\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "\n",
    "def train_loader(dataset, batch_size, num_workers=4, pin_memory=False, normalize=None):\n",
    "\n",
    "    return data.DataLoader(\n",
    "        dataset= dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "\n",
    "def test_loader(dataset, batch_size, num_workers=4, pin_memory=False):\n",
    "\n",
    "    return data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3: 测试指标\n",
    "import numpy as np\n",
    "def cal_confusion_matrix(output, target, n_class):  ##横轴:Gt， 竖轴:Pred\n",
    "    mask = (output >= 0) & (target < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * target[mask].astype(int) +\n",
    "        output[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def cal_pa(mask, n ):\n",
    "    return np.nanmean( np.diag(mask)[:(n-1)]/( np.sum(mask,0)[:(n-1)] ) )\n",
    "def cal_iou(mask, n, iou_vars):\n",
    "    iou_var = np.diag(mask)[:(n-1)]/( np.sum(mask,0)[:(n-1)]+np.sum(mask,1)[:(n-1)]-np.diag(mask)[:(n-1)] )\n",
    "    result = np.nanmean( iou_var )\n",
    "    iou_vars += iou_var\n",
    "    # print(\"IOU_VAR\", iou_var)\n",
    "    # print(\"Gt: \", np.sum(mask,0)[:(n-1)])\n",
    "    # print(\"Pred: \", np.sum(mask,1)[:(n-1)])\n",
    "    return result, iou_vars\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 4: 训练pipeline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from timm.utils import AverageMeter\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as v_util\n",
    "import time\n",
    "\n",
    "class Manager(object):\n",
    "    \"\"\"Handles training and pruning.\"\"\"\n",
    "\n",
    "    def __init__(self, args, model):\n",
    "        self.args = args\n",
    "        self.cuda = args.cuda\n",
    "        self.model = model\n",
    "        self.savename = args.savename\n",
    "        self.epoch_idx = 0\n",
    "\n",
    "        train_data = CityscapesDataset(root=\"./data\", args = self.args, split='train')\n",
    "\n",
    "        test_data = CityscapesDataset(root='./data', args = self.args, split='val')\n",
    "\n",
    "\n",
    "        self.train_loader = train_loader(train_data, batch_size=args.batch_size, num_workers=args.num_workers)\n",
    "        self.test_loader = test_loader(test_data, batch_size=args.batch_size, num_workers=args.num_workers)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=15)\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.args.lr)\n",
    "\n",
    "        self.train_loss = AverageMeter()\n",
    "        self.test_loss = AverageMeter()\n",
    "        self.test_miou = AverageMeter()\n",
    "        self.test_pa = AverageMeter()\n",
    "        self.inference_time = AverageMeter()\n",
    "        self.fin_ious = Average_IOU_Meter(self.args, batches= len(self.test_loader))\n",
    "\n",
    "        self.best_accuracy = 0\n",
    "\n",
    "        self.list_train_loss = []\n",
    "        self.list_test_loss = []\n",
    "        self.list_test_pa = []\n",
    "        self.list_test_miou = []\n",
    "        self.list_inference_time = []\n",
    "        self.arr_fin_ious = np.zeros( (args.epoches, args.num_classes -1 ))\n",
    "        self.iou_vars = np.zeros( (args.batch_size, args.num_classes-1 ) )\n",
    "        self.ious = np.zeros( (args.num_classes-1, ) )\n",
    "        self.writer = SummaryWriter('./logs')\n",
    "        \n",
    "        if args.intel_optimize:\n",
    "            import intel_extension_for_pytorch as ipex\n",
    "            self.model, self.optimizer = ipex.optimize(self.model, optimizer = self.optimizer, dtype=torch.bfloat16)\n",
    "        \n",
    "        if args.pytorch_quant == True and args.intel_quant == False:\n",
    "            self.quant_pyt_helper()\n",
    "        \n",
    "        if args.intel_quant:\n",
    "            self.quant_intel_helper()\n",
    "\n",
    "    def do_epoch(self, eidx):\n",
    "        \"\"\"Trains model for one epoch.\"\"\"\n",
    "        self.train_loss.reset()\n",
    "        for epoch_idx, ( batch, target_mask ) in tqdm(enumerate(self.train_loader),\n",
    "                                                                total= len(self.train_loader) ):\n",
    "            self.do_batch( batch, target_mask )\n",
    "\n",
    "        self.list_train_loss.append(self.train_loss.avg)\n",
    "        self.writer.add_scalar('train/loss', self.train_loss.avg, eidx)\n",
    "        self.writer.flush()\n",
    "\n",
    "\n",
    "    def do_batch(self, batch, label):\n",
    "        \"\"\"Runs model for one batch.\"\"\"\n",
    "        if self.cuda:\n",
    "            batch = batch.cuda()\n",
    "            label = label.cuda()\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(batch)\n",
    "        # print(output[0].shape)\n",
    "        # print(\"Output\", output[0, :, 0, 0])\n",
    "        # print(\"Label\", label[0,0,0])\n",
    "        # print(\"Output\", output[0, :, 0, 0])\n",
    "        # print(torch.any(torch.isinf(output)))\n",
    "        # print(torch.any(torch.isinf(label)))\n",
    "        loss = self.criterion(output, label)\n",
    "        # print(\"Loss: \", loss)\n",
    "        self.train_loss.update(loss.item(), output.shape[0])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Performs training and evaling\"\"\"\n",
    "\n",
    "        if self.args.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "        for idx in range(self.args.epoches):\n",
    "            self.epoch_idx = idx + 1\n",
    "            print('Epoch: %d' % (self.epoch_idx))\n",
    "\n",
    "            ## Training\n",
    "            self.model.train()\n",
    "            self.do_epoch(self.epoch_idx)\n",
    "            \n",
    "            self.save_model()\n",
    "\n",
    "            ## Testing\n",
    "            self.eval(idx)\n",
    "\n",
    "            ## Save model\n",
    "            if self.test_miou.avg > self.best_accuracy:\n",
    "                print(\" Best model trained at {} epoches.\".format( self.epoch_idx))\n",
    "                self.best_accuracy = self.test_miou.avg\n",
    "                self.save_model()\n",
    "\n",
    "            ## collect experimental data\n",
    "\n",
    "        if self.args.save_loss:\n",
    "      #      np.save('./saved/train_loss.npy', np.array(self.list_train_loss))\n",
    "            print(self.list_train_loss)\n",
    "            np.save('./saved/test_loss.npy', self.list_test_loss)\n",
    "            np.save('./saved/pa.npy', self.list_test_pa)\n",
    "            np.save('./saved/iou.npy', self.list_test_miou)\n",
    "\n",
    "    def cal_iou(self, mask, ci):\n",
    "        iou_var = np.diag(mask)[:(self.args.num_classes - 1)] / (\n",
    "                    np.sum(mask, 0)[:(self.args.num_classes - 1)] + np.sum(mask, 1)[:(self.args.num_classes - 1)]\n",
    "                    - np.diag(mask)[:(self.args.num_classes - 1)])\n",
    "        result = np.nanmean(iou_var)\n",
    "        self.iou_vars[ci,:] = iou_var\n",
    "        # print(\"IOU_VAR\", iou_var)\n",
    "        # print(\"Gt: \", np.sum(mask,0)[:(n-1)])\n",
    "        # print(\"Pred: \", np.sum(mask,1)[:(n-1)])\n",
    "        return result\n",
    "\n",
    "    def eval(self, idx, record = True, visual = False):\n",
    "        self.model.eval()\n",
    "\n",
    "        self.test_loss.reset()\n",
    "        self.test_miou.reset()\n",
    "        self.test_pa.reset()\n",
    "        self.fin_ious.reset()\n",
    "        self.inference_time.reset()\n",
    "\n",
    "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "        with torch.no_grad(), torch.cpu.amp.autocast():\n",
    "            for bidx, (batch, label) in enumerate(tqdm(self.test_loader, desc='Eval')):\n",
    "                if self.cuda:\n",
    "                    batch = batch.cuda()\n",
    "                    label = label.cuda()\n",
    "                \n",
    "                starter = time.time()\n",
    "                output = self.model(batch)  ## [batch_size, 30, 512,512]\n",
    "                ender = time.time()\n",
    "\n",
    "                curr_time = ender - starter\n",
    "                self.inference_time.update(curr_time)\n",
    "                self.test_loss.update( self.criterion(output, label).item() )\n",
    "\n",
    "                miou = 0\n",
    "                pa = 0\n",
    "                for ci in range(output.shape[0]): ## to each img\n",
    "                    label_pred = np.array ( torch.squeeze( torch.argmax( torch.squeeze(output[ci]), dim= 0) ).to('cpu') )\n",
    "                #    print(\"fs\", label_pred.shape)\n",
    "                    if bidx%10 == 0 and visual:\n",
    "                        visual_tensor = utils.class_to_rgb(label_pred)\n",
    "                        img_pred = v_util.make_grid(visual_tensor.long()).cpu().numpy()\n",
    "                        img_label = v_util.make_grid(batch[ci].long()).cpu().numpy()\n",
    "                        plt.imshow(np.transpose(img_pred, (1, 2, 0)))\n",
    "                        plt.show()\n",
    "                        plt.imshow(np.transpose(img_label, (1, 2, 0)))\n",
    "                        plt.show()\n",
    "\n",
    "                    label_true = np.array ( label[ci].to('cpu') )\n",
    "                    mask = cal_confusion_matrix(label_pred, label_true, self.args.num_classes)\n",
    "                    iou = self.cal_iou(mask,ci)\n",
    "                    miou += iou\n",
    "                    pa += cal_pa(mask, self.args.num_classes)\n",
    "\n",
    "                for i in range(self.args.num_classes-1):\n",
    "                    self.ious[i] = np.nanmean(self.iou_vars[:,i])\n",
    "\n",
    "                if bidx != len(self.test_loader)-1:\n",
    "                    self.fin_ious.update(self.ious)\n",
    "                self.test_miou.update(miou/output.shape[0], output.shape[0])\n",
    "                self.test_pa.update(pa/output.shape[0], output.shape[0])\n",
    "\n",
    "        avg_ivs = self.fin_ious.cal_avg()\n",
    "        print(\"avg_iou_var\", avg_ivs)\n",
    "        print(\"avg_miou\", self.test_miou.avg )\n",
    "        print(\"avg_pa\", self.test_pa.avg)\n",
    "\n",
    "        if record:\n",
    "            self.list_test_loss.append(self.test_loss.avg)\n",
    "            self.list_test_miou.append(self.test_miou.avg)\n",
    "            self.list_test_pa.append(self.test_pa.avg)\n",
    "            self.list_inference_time.append(self.inference_time)\n",
    "            self.arr_fin_ious[idx, :] = avg_ivs\n",
    "\n",
    "            self.writer.add_scalar('test/loss', self.test_loss.avg , self.epoch_idx)\n",
    "            self.writer.add_scalar('test/PA', self.test_pa.avg, self.epoch_idx)\n",
    "            self.writer.add_scalar('test/IOU', self.test_miou.avg, self.epoch_idx)\n",
    "            self.writer.flush()\n",
    "\n",
    "            print( self.list_test_loss)\n",
    "            np.save('./saved/test_loss.npy', self.list_test_loss)\n",
    "            np.save('./saved/pa.npy', self.list_test_pa)\n",
    "            np.save('./saved/iou.npy', self.list_test_miou)\n",
    "            np.save('./saved/inference_time.npy', self.list_inference_time)\n",
    "            np.save('./saved/arr_ious.npy', self.arr_fin_ious)\n",
    "        \n",
    "        return self.test_miou.avg\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Saves model to file.\"\"\"\n",
    "        base_model = self.model\n",
    "        ckpt = {\n",
    "            'args': self.args,\n",
    "            'model': base_model,\n",
    "        }\n",
    "\n",
    "        # Save to file.\n",
    "        torch.save(ckpt, self.savename + '.pt')\n",
    "    \n",
    "    def quant_intel_helper(self):\n",
    "        import neural_compressor\n",
    "        from neural_compressor import PostTrainingQuantConfig\n",
    "        from neural_compressor import quantization\n",
    "        conf = PostTrainingQuantConfig(backend=\"ipex\")\n",
    "        q_model = quantization.fit(self.model,\n",
    "                                    conf,\n",
    "                                    calib_dataloader=self.test_loader,\n",
    "                                    eval_func=self.eval(idx = 0) )\n",
    "    \n",
    "    def quant_pyt_helper(self):\n",
    "        quantization_config = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        self.model = torch.quantization.quantize_dynamic(\n",
    "        model=self.model,  \n",
    "        qconfig_spec= {nn.Conv2d},  \n",
    "        dtype=torch.qint8)  \n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Part 5:超参数\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.num_classes = 13\n",
    "        self.cuda = False\n",
    "        self.batch_size = 8\n",
    "        self.num_worker = 4\n",
    "        self.lr = 0.01\n",
    "        self.epoches = 400 \n",
    "        self.intel_optimize = False\n",
    "        self.save_loss = True\n",
    "        self.savename = './saved/hrnetv2'\n",
    "        self.intel_quant = False \n",
    "        self.pytorch_quant = False\n",
    "        self.num_workers = 4\n",
    "    \n",
    "    def set_save_path(self, save_path):\n",
    "        self.savename = save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb53004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 6: 训练\n",
    "from nets import seg_unet\n",
    "from nets import hrnet\n",
    "args = Args()\n",
    "\n",
    "args.set_save_path('./saved/saved_model/seg_unet')\n",
    "model_unet = seg_unet.Seg_unet(3,args.num_classes,64)\n",
    "manager = Manager(args, model)\n",
    "manager.train()\n",
    "\n",
    "args.set_save_path('./saved/saved_model/hrnetv2')\n",
    "model_hrnet = hrnet.HRnet(num_classes=args.num_classes, backbone=\"hrnetv2_w48\", pretrained=True)\n",
    "manager = Manager(args, model)\n",
    "manager.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7db2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 7: 测试\n",
    "ckpt = torch.load(\"./saved/hrnetv2.pt\")\n",
    "model = ckpt[\"model\"]\n",
    "manager = Manager(args, model)\n",
    "manager.eval(idx= 0 , record=False, visual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ed48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 8: 量化\n",
    "\n",
    "args.intel_quant = True  ## Intel 量化工具测试\n",
    "ckpt = torch.load(\"./saved/hrnetv2.pt\")\n",
    "model = ckpt[\"model\"]\n",
    "manager = Manager(args, model)\n",
    "manager.eval(idx= 0 , record=False, visual=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
